\section{Description des classifieurs utilisés}

	Il nous était possible d'utiliser deux sortes d'apprentissage sur nos données. L'apprentissage non-supervisé apprend uniquement à partir des attributs, sans tenir compte des labels. Cela permet par exemple de faire du clustering pour regrouper les données en différentes classes. Nous avons appliqué cette méthode d'apprentissage en utilisant l'algorithme des k-moyennes sur nos données.\\

	L'apprentissage supervisé apprend en se basant sur les attributs mais en utilisant également les labels que nous connaissons. Cette technique d'apprentissage paraît donc plus adaptée dans notre cas. Différentes méthodes existent, nous avons choisis de nous concentrer sur les SVM (\emph{Support Vector Machines} ou séparateurs à vaste marge) pour réaliser notre classification en apprentissage supervisé. Ils sont souvent utilisés pour résoudre des problèmes de discrimination, c'est-à-dire savoir à quelle classe appartient un échantillon, et c'est exactement le problème auquel nous sommes confrontés. Le SVM va chercher à tracer une limite entre les classes des données d'apprentissage en maximisant la marge entre cette limite et chaque classe. Les classes de nouvelles données seront ensuite attribuées selon le côté du quel se trouvent les nouvelles données. La limite entre les classes peut-être en ligne droite, dans le cas d'un SVM linéaire, ou plus compliquée dans le cas d'un SVM avec noyau.\\

	Dans un premier temps nous avons travaillé sur deux classes, ce qui est le problème le plus simple à résoudre avec des SVM. Nous avons pour cela réalisé deux SVM, un SVM linéaire et un SVM gaussien. Nous avons effectué de la validation croisée afin d'identifier les hyper-paramètres (C pour le SVM linéaire, et C et sigma pour le SVM gaussien).

	Dans un second temps nous avons travaillé sur un jeu de données contenant 4 classes et des données \emph{unlabeled} représentant une cinquième classe. Les données unlabeled ont été retirées de l'ensemble de l'apprentissage car elle pouvait correspondre à n'importe quelle classe et donc perturber le SVM.
	Nous avons ensuite utilisé deux méthodes permettant de faire de la classification avec plus de deux classes :

	\begin{itemize}
	\item La méthode \emph{one-versus-all} consiste à construire M classifieurs binaires en attribuant le label 1 aux échantillons de l'une des classes et le label -1 à toutes les autres. En phase de test, la classe est determinées grâce à un vote à la majorité entre les différents SVM.
	\item La méthode \emph{one-versus-one} consiste à construire $\frac{M(M-1)}{2}$ classifieurs binaires en confrontant chacune des $M$ classes. En phase de test, l'échantillon à classer est analysé par chaque classifieur et un vote majoritaire permet de déterminer sa classe.\\
	\end{itemize}


\section{Données et pré-traitement}
\subsection{Extraction des données}

	Les données sont extraites à partir de ROS. Il s'agit d'un outil qui sert à traiter les \texttt{.tm}, qui sont des vidéos en 3D, pour en extraire des nuages de points au format pcd. Ici, les vidéos que nous avons sont filmées depuis un véhicule dans une zone urbaine.\\

	Vu qu’il y a des erreurs dans la compilation du C++ pour lancer ROS, M. Guerrero nous a fourni directement les archives contenant les pcd.\\

\subsection{Format des données}

	Les données que nous avons sont une multitude d'imagettes (frames) de chaque classe. Ce sont des sortes de captures d'écran d'une vidéo à un instant donné, mais en trois dimensions.\\

	Soit$ X_{i}$ la ième imagette, on a :

	$  X_{i} \in \reels^{n_{i}*4} $, avec 50 $\leq n_{i} \leq 300$
	En effet, chaque imagette a ses coordonnées $x$, $y$, $z$ et une valeur d'intensité. \\

\subsection{Jeu de données dish area}

	Ce jeu de données contient 30242 imagettes réparties dans 91 séquences de 2 classes différentes : background et car. On remarquera cependant que les données ne sont pas également réparties entre ces classes : il y a 26715 imagettes de la classe background et 3527 de la classe car.

\subsection{Jeu de données lomita}

	Ce jeu de données contient 75817 imagettes réparties dans 155 séquences de 5 classes différentes : background, bicyclist, car, pedestrian et unlabeled. On remarquera cependant que les données ne sont pas également réparties entre ces 5 classes : il y a 105 séquences de classe background, 5 bicyclist, 20 car, 9 pedestrian et 16 unlabeled. \\

	La classe unlabeled n'est pas une classe en soit, elle regroupe les imagettes n'ayant pas pu être classées dans une des 4 autres classes. Ces données ont donc été supprimées du jeu de données car elles auraient pu fausser l'apprentissage. \\

	Nous avons également eu l'idée de ré-équilibrer les classes en utilisant seulement une partie de la classe background mais ce pré-traitement ne semble pas pertinent puisqu'il amène a des taux d'erreur de test plus élevé. C'est pourquoi nous avons gardé des classes déséquilibrées. \\


\section{Résultats obtenus}


	\subsection{Classification sur deux classes (dish area)}
		\subsubsection{K-moyennes}
			Nous avons utilisé l'algorithme kmeans de matlab pour former des clusters et les comparer avec les classes connues. Nous obtenons un taux d'erreur de 8.71\%, ce qui est un bon résultat pour un algorithme non-supervisé. Notre matrice de confusion est la suivante :

			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  & Prédiction : background & Prédiction : car \\
				  \hline
				  Vérité : background & 25054 & 1661 \\
				  \hline
				  Vérité : car & 974 & 2553 \\
				  \hline
				\end{tabular}
			\end{center}

			On constate que les erreurs sont plutôt bien réparties, c'est-à-dire qu'il n'y a pas plus d'erreur pour une classe pour une autre, ce qui était un risque étant donné que nos classes n'ont pas le même effectif.

		\subsubsection{SVM linéaire}
			Nous avons créé un SVM linéaire en effectuant de la validation croisée pour le paramètre C. Nous avons pour cela utilisé la fonction monqp de la toolbox SVM-KM. En l’exécutant sur la totalité des données nous obtenons un taux d'erreur de A changer !!!\%. Notre matrice de confusion est la suivante :
			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  & Prédiction : background & Prédiction : car \\
				  \hline
				  Vérité : background & A changer !!! & A changer !!! \\
				  \hline
				  Vérité : car & A changer !!! & A changer !!! \\
				  \hline
				\end{tabular}
			\end{center}

			COMMENTAIRE !
		\subsubsection{SVM gaussien}
			Nous avons créé un SVM gaussien en effectuant de la validation croisée pour le paramètre C et le paramètre sigma. Pour le paramètre C nous avons choisi d'utiliser une valeur différente pour les deux classes. Nous avons donc effectuer la validation séparément pour ces deux valeurs de C. En l’exécutant sur la totalité des données nous obtenons un taux d'erreur de A changer !!!\%. Notre matrice de confusion est la suivante :
			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  & Prédiction : background & Prédiction : car \\
				  \hline
				  Vérité : background & A changer !!! & A changer !!! \\
				  \hline
				  Vérité : car & A changer !!! & A changer !!! \\
				  \hline
				\end{tabular}
			\end{center}

			COMMENTAIRE !

	\subsection{Classification sur 4 classes (lomita)}
		Nous n'avons pas pu faire tourner nos algorithmes sur la totalité des données, nos machines n'étant pas assez puissantes. Nous avons donc réduit la taille des données et avons obtenu des résultats déjà satisfaisants. Notre dataset actuel est composé de 1722 observations ayant chacune 10 attributs.

		\subsubsection{K-moyennes}
			Nous avons utilisé l'algorithme kmeans de matlab pour former des clusters et les comparer avec les classes connues. Cet algorithme étant très optimisé, c'est le seul que nous avons pu exécuter sur la totalité de nos données. Nous obtenons un taux d'erreur de 23.9\%. Ce taux est très élevé. En effet, la classe background étant sur-représentée, un algorithme prédisant tout le temps la classe background aurait de meilleures performances (12.7 \%).

			\begin{center}
				\begin{tabular}{|l||c|c|c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
				  \hline
				  background & 51258 & 8845 & 0 & 0 \\
				  \hline
				  bicyclist & 78 & 880 & 0 & 0 \\
				   \hline
				  car & 1964 & 3973 & 0 & 0 \\
				   \hline
				  pedestrian & 708 & 1123 & 0 & 0 \\
				  \hline
				\end{tabular}
			\end{center}

			On remarque que les résultats sur les deux premières classes sont convenables mais les deux dernières classes ne sont jamais prédites.

		\subsubsection{SVM one-versus-one}
			Nous avons mis en place notre propre SVM One versus one. Cette méthode met en place plusieurs SVM comparant les classes une à une, puis un vote à la majorité nous permet de prédire la classe pour une nouvelle donnée. Cette méthode étant coûteuse en temps, nous avons choisi d'utiliser uniquement des SVMs linéaire. Nous avons retenu une version qui effectue la validation croisée du C sur l'ensemble du SVM multi-classe, le même C est donc retenu pour tous les SVM. Nous avons également créé une autre version, pour laquelle la validation croisée est effectuée sur chaque SVM individuellement, qui obtient un taux d'erreur légèrement meilleur mais pour un temps de calcul plus long. Cette version n'est pas la version retenue à cause des temps de calcul, elle ne sera donc pas commentée ici mais elle est disponible dans le dossier.\\

			Nous obtenons 4.4 \% d'erreurs sur le petit jeu de données. Notre matrice de confusion est la suivante :

			\begin{center}
				\begin{tabular}{|l||c|c|c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
				  \hline
				  background & 372 & 3 & 0 & 0 \\
				  \hline
				  bicyclist & 4 & 2 & 0 & 0 \\
				   \hline
				  car & 1 & 0 & 36 & 0 \\
				   \hline
				  pedestrian & 10 & 1 & 0 & 0 \\
				  \hline
				\end{tabular}
			\end{center}

		On remarque que, même si notre taux d'erreur est bon, les erreurs ne sont pas bien réparties entre les classes. Notre SVM ne prédit jamais la bonne classe pour les imagettes de classe pedestrian et les résultats sont également faibles pour la classe bicyclist.

		\subsubsection{SVM one-versus-all}
			Nous avons mis en place un SVM one versus all en utilisant les fonction svmclass et svmval, permettant respectivement d’entraîner les SVMs et d'obtenir des prédictions. Grâce à ces fonctions nous avons créé des SVMs comparant chaque classe aux autres, puis la classe des nouvelles données étaient prédites grâce à un vote à la majorité. Nous n'avons pas ajouté de validation croisée sur ce SVM car cela était trop coûteux en temps.\\

			Nous avons dans un premier temps utilisé un SVM gaussien où nous avons obtenu un taux d'erreurs de 4.65 \%. La matrice de confusion est la suivante :
			\begin{center}
				\begin{tabular}{|l||c|c|c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
				  \hline
				  background & 595 & 1 & 0 & 5 \\
				  \hline
				  bicyclist & 4 & 1 & 0 & 4 \\
				   \hline
				  car & 4 & 0 & 55 & 0 \\
				   \hline
				  pedestrian & 14 & 0 & 0 & 4 \\
				  \hline
				\end{tabular}
			\end{center}

			On remarque que les résultats sont plutôt bons pour les classes background et car mais mois pour les deux autres, qui sont moins représentées.
