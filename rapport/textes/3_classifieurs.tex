\section{Description des classifieurs utilisés}

	Il nous était possible d'utiliser deux sortes d'apprentissage sur nos données. L'apprentissage non-supervisé apprend uniquement à partir des attributs, sans tenir compte des labels. Cela permet par exemple de faire du clustering pour regrouper les données en différentes classes. Nous avons appliqué cette méthode d'apprentissage en utilisant l'algorithme des k-moyennes sur nos données.\\

	L'apprentissage supervisé apprend en se basant sur les attributs mais en utilisant également les labels que nous connaissons. Cette technique d'apprentissage paraît donc plus adaptée dans notre cas. Différentes méthodes existent, nous avons choisis de nous concentrer sur les SVM (\emph{Support Vector Machines} ou séparateurs à vaste marge) pour réaliser notre classification en apprentissage supervisé. Ils sont souvent utilisés pour résoudre des problèmes de discrimination, c'est-à-dire savoir à quelle classe appartient un échantillon, et c'est exactement le problème auquel nous sommes confrontés. Le SVM va chercher à tracer une limite entre les classes des données d'apprentissage en maximisant la marge entre cette limite et chaque classe. Les classes de nouvelles données seront ensuite attribuées selon le côté du quel se trouvent les nouvelles données. La limite entre les classes peut-être en ligne droite, dans le cas d'un SVM linéaire, ou plus compliquée dans le cas d'un SVM avec noyau.\\

	Dans un premier temps nous avons travaillé sur deux classes, ce qui est le problème le plus simple à résoudre avec des SVM. Nous avons pour cela réalisé deux SVM, un SVM linéaire et un SVM gaussien. Nous avons effectué de la validation croisée afin d'identifier les hyper-paramètres (C pour le SVM linéaire, et C et sigma pour le SVM gaussien).

	Dans un second temps nous avons travaillé sur un jeu de données contenant 4 classes et des données \emph{unlabeled} représentant une cinquième classe. Les données unlabeled ont été retirées de l'ensemble de l'apprentissage car elle pouvait correspondre à n'importe quelle classe et donc perturber le SVM.
	Nous avons ensuite utilisé deux méthodes permettant de faire de la classification avec plus de deux classes :

	\begin{itemize}
	\item La méthode \emph{one-versus-all} consiste à construire M classifieurs binaires en attribuant le label 1 aux échantillons de l'une des classes et le label -1 à toutes les autres. En phase de test, la classe est determinées grâce à un vote à la majorité entre les différents SVM.
	\item La méthode \emph{one-versus-one} consiste à construire $\frac{M(M-1)}{2}$ classifieurs binaires en confrontant chacune des $M$ classes. En phase de test, l'échantillon à classer est analysé par chaque classifieur et un vote majoritaire permet de déterminer sa classe.\\
	\end{itemize}


\section{Données et pré-traitement}
\subsection{Extraction des données}

	Les données sont extraites à partir de ROS. Il s'agit d'un outil qui sert à traiter les \texttt{.tm}, qui sont des vidéos en 3D, pour en extraire des nuages de points au format pcd. Ici, les vidéos que nous avons sont filmées depuis un véhicule dans une zone urbaine.\\

	Vu qu’il y a des erreurs dans la compilation du C++ pour lancer ROS, M. Guerrero nous a fourni directement les archives contenant les pcd.\\

\subsection{Format des données}

	Les données que nous avons sont une multitude d'imagettes (frames) de chaque classe. Ce sont des sortes de captures d'écran d'une vidéo à un instant donné, mais en trois dimensions.\\

	Soit$ X_{i}$ la ième imagette, on a :

	$  X_{i} \in \reels^{n_{i}*4} $, avec 50 $\leq n_{i} \leq 300$
	En effet, chaque imagette a ses coordonnées $x$, $y$, $z$ et une valeur d'intensité. \\

\subsection{Jeu de données dish area}

	Ce jeu de données contient 30242 imagettes réparties dans 91 séquences de 2 classes différentes : background et car. On remarquera cependant que les données ne sont pas également réparties entre ces classes : il y a 26715 imagettes de la classe background et 3527 de la classe car.

\subsection{Jeu de données lomita}

	Ce jeu de données contient 75817 imagettes réparties dans 155 séquences de 5 classes différentes : background, bicyclist, car, pedestrian et unlabeled. On remarquera cependant que les données ne sont pas également réparties entre ces 5 classes : il y a 60103 imagettes de classe background, 958 bicyclist, 5937 car, 1831 pedestrian et 6984 unlabeled. \\

	La classe unlabeled n'est pas une classe en soit, elle regroupe les imagettes n'ayant pas pu être classées dans une des 4 autres classes. Ces données ont donc été supprimées du jeu de données car elles auraient pu fausser l'apprentissage. \\

	Nous avons également ré-équilibré les classes en utilisant seulement une partie de la classe background afin que la différence d'effectif entre cette classe et les autres ne soit pas trop importante. Nous avons donc pris aléatoirement 7000 données de la classe background sur les 60103 présente à l'origine, ce qui correspond à une sélection de 11,65\%. Ce changement a nettement amélioré nos résultats. Nos machines n'étant pas assez puissantes, nous n'avons pas pu faire tourner nos propres algorithmes sur la totalité des données sans retirer des données de la classe background. Nous les avons cependant exécutés sur une partie des données (1722 observations) non ré-équilibrées et avons conservé ces résultats à titre de comparaison. \\


\section{Résultats obtenus}


	\subsection{Classification sur deux classes (dish area)}
		\subsubsection{K-moyennes}
			Nous avons utilisé l'algorithme kmeans de matlab pour former des clusters et les comparer avec les classes connues. Nous obtenons un taux d'erreur de 8.71\%, ce qui est un bon résultat pour un algorithme non-supervisé. Notre matrice de confusion est la suivante :

			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & car \\
				  \hline
				  background & 25054 & 1661 \\
				  \hline
				  car & 974 & 2553 \\
				  \hline
				\end{tabular}
			\end{center}

			On constate que les erreurs sont plutôt bien réparties, c'est-à-dire qu'il n'y a pas plus d'erreur pour une classe pour une autre, ce qui était un risque étant donné que nos classes n'ont pas le même effectif.

		\subsubsection{SVM linéaire}
			Nous avons créé un SVM linéaire en effectuant de la validation croisée pour le paramètre C. Nous avons pour cela utilisé la fonction monqp de la toolbox SVM-KM. En l’exécutant sur la totalité des données nous obtenons un taux d'erreur de A changer !!!\%. Notre matrice de confusion est la suivante :
			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & car \\
				  \hline
				  background & A changer !!! & A changer !!! \\
				  \hline
				  car & A changer !!! & A changer !!! \\
				  \hline
				\end{tabular}
			\end{center}

			COMMENTAIRE !
		\subsubsection{SVM gaussien}
			Nous avons créé un SVM gaussien en effectuant de la validation croisée pour le paramètre C et le paramètre sigma. Pour le paramètre C nous avons choisi d'utiliser une valeur différente pour les deux classes. Nous avons donc effectuer la validation séparément pour ces deux valeurs de C. En l’exécutant sur la totalité des données nous obtenons un taux d'erreur de A changer !!!\%. Notre matrice de confusion est la suivante :
			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & car \\
				  \hline
				  background & A changer !!! & A changer !!! \\
				  \hline
				  car & A changer !!! & A changer !!! \\
				  \hline
				\end{tabular}
			\end{center}

			COMMENTAIRE !

	\subsection{Classification sur quatre classes (lomita)}

		\subsubsection{K-moyennes}
			Nous avons utilisé l'algorithme kmeans de matlab pour former des clusters et les comparer avec les classes connues. Cet algorithme étant très optimisé, c'est le seul que nous avons pu exécuter sur la totalité de nos données. Nous obtenons un taux d'erreur de 23.9\%. Ce taux est très élevé. En effet, la classe background étant sur-représentée, un algorithme prédisant tout le temps la classe background aurait de meilleures performances (12.7 \%).

			\begin{center}
				\begin{tabular}{|l||c|c|c|c|}
				  \hline
				  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
				  \hline
				  background & 51258 & 8845 & 0 & 0 \\
				  \hline
				  bicyclist & 78 & 880 & 0 & 0 \\
				   \hline
				  car & 1964 & 3973 & 0 & 0 \\
				   \hline
				  pedestrian & 708 & 1123 & 0 & 0 \\
				  \hline
				\end{tabular}
			\end{center}

			On remarque que les résultats sur les deux premières classes sont convenables mais les deux dernières classes ne sont jamais prédites.

		\subsubsection{SVM one-versus-one}

			Nous avons mis en place notre propre SVM One versus one. Cette méthode met en place plusieurs SVM comparant les classes une à une, puis un vote à la majorité nous permet de prédire la classe pour une nouvelle donnée. Cette méthode étant coûteuse en temps, nous avons choisi d'utiliser uniquement des SVMs linéaire. Nous avons retenu une version qui effectue la validation croisée du C sur l'ensemble du SVM multi-classe, le même C est donc retenu pour tous les SVM. Nous avons également créé une autre version, pour laquelle la validation croisée est effectuée sur chaque SVM individuellement, qui obtient un taux d'erreur légèrement meilleur mais pour un temps de calcul plus long. Cette version n'est pas la version retenue à cause des temps de calcul, elle ne sera donc pas commentée ici mais elle est disponible dans le dossier.
			
			\paragraph{Données non rééquilibrées :}
				Nous obtenons 4.4 \% d'erreurs sur le petit jeu de données. Notre matrice de confusion est la suivante :

				\begin{center}
					\begin{tabular}{|l||c|c|c|c|}
					  \hline
					  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
					  \hline
					  background & 372 & 3 & 0 & 0 \\
					  \hline
					  bicyclist & 4 & 2 & 0 & 0 \\
					   \hline
					  car & 1 & 0 & 36 & 0 \\
					   \hline
					  pedestrian & 10 & 1 & 0 & 0 \\
					  \hline
					\end{tabular}
				\end{center}

				On remarque que, même si notre taux d'erreur est bon, les erreurs ne sont pas bien réparties entre les classes. Notre SVM ne prédit jamais la bonne classe pour les imagettes de classe pedestrian et les résultats sont également faibles pour la classe bicyclist.

			\paragraph{Données rééquilibrées :}
				Nous obtenons 0 \% d'erreurs sur le jeu de données rééquilibré, ce qui est très surprenant. Notre matrice de confusion est la suivante :

				\begin{center}
					\begin{tabular}{|l||c|c|c|c|}
					  \hline
					  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
					  \hline
					  background & 1750 & 0 & 0 & 0 \\
					  \hline
					  bicyclist & 0 & 239 & 0 & 0 \\
					   \hline
					  car & 0 & 0 & 1484 & 0 \\
					   \hline
					  pedestrian & 0 & 0 & 0 & 457 \\
					  \hline
					\end{tabular}
				\end{center}
			\vspace{10 mm}

		\subsubsection{SVM one-versus-all}
			Nous avons mis en place un SVM one versus all en utilisant les fonction svmclass et svmval, permettant respectivement d’entraîner les SVMs et d'obtenir des prédictions. Grâce à ces fonctions nous avons créé des SVMs comparant chaque classe aux autres, puis la classe des nouvelles données étaient prédites grâce à un vote à la majorité. Nous n'avons pas ajouté de validation croisée sur ce SVM car cela était trop coûteux en temps. Nous avons utilisé des SVM avec noyau gaussien.

			\paragraph{Données non rééquilibrées :}
				Nous avons obtenu un taux d'erreurs de 4.65 \% sur le petit jeu de données. La matrice de confusion est la suivante :
				\begin{center}
					\begin{tabular}{|l||c|c|c|c|}
					  \hline
					  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
					  \hline
					  background & 595 & 1 & 0 & 5 \\
					  \hline
					  bicyclist & 4 & 1 & 0 & 4 \\
					   \hline
					  car & 4 & 0 & 55 & 0 \\
					   \hline
					  pedestrian & 14 & 0 & 0 & 4 \\
					  \hline
					\end{tabular}
				\end{center}

				On remarque que les résultats sont plutôt bons pour les classes background et car mais moins pour les deux autres, qui sont moins représentées.

			\paragraph{Données non rééquilibrées :}
				Nous avons obtenu un taux d'erreurs de 0.175 \%. La matrice de confusion est la suivante :
				\begin{center}
					\begin{tabular}{|l||c|c|c|c|}
					  \hline
					  \backslashbox{Vérité}{Prédiction}& background & bicyclist & car & pedestrian \\
					  \hline
					  background & 2800 & 0 & 0 & 0 \\
					  \hline
					  bicyclist & 0 & 383 & 0 & 0 \\
					   \hline
					  car & 1 & 4 & 2369 & 0 \\
					   \hline
					  pedestrian & 5 & 0 & 1 & 726 \\
					  \hline
					\end{tabular}
				\end{center}

				Ces résultats sont vraiment bons.


	\subsection{Commentaire des résultats}
		RAJOUTER UNE CONLUSION SUR LES 2 CLASSES ?

		Nous avons pu voir que, si la classification non-supervisée donne des résultats convenables sur deux classes, les résultats deviennent vraiment faibles pour la classification multi-classe.

		Les SVM obtiennent de bons résultats. Lorsque les données ne sont pas rééquilibrées il y a des erreurs importantes sur les classes les moins représentées (bicyclist et pedestrian). Les méthodes que nous avons vues ne permettent pas de classifier convenablement ces classes en gardant les données telles quelles. Ces erreurs disparaissent cependant lorsque nous diminuons le nombre d'observations pour la classe background. Les erreurs des autres classes diminuent considérablement sans que cela ait de conséquences sur la classification de la classe background, ce qui entraîne une diminution significative de l'erreur. Les résultats obtenus, avec des erreurs inférieures à 0.2 \% ou nulles, sont remarquables.

		Ces résultats sont toute fois à nuancer puisque des tirages aléatoires sont réalisés pour rééquilibrer la classe background et pour construire les ensemble d'apprentissage, de validation et de test. Des tirages différents pourraient donc amener à des résultats légèrement différents. Il pourrait être intéressant d'exécuter les algorithmes plusieurs fois avec des tirages différents afin de calculer les différentes erreurs et d'en faire la moyenne. Cela serait cependant coûteux en temps, à raison d'une heure par exécution.

