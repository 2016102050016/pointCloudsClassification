\section{Description des classifieurs utilisés}

	Il nous était possible d'utiliser deux sortes d'apprentissage sur nos données. L'apprentissage non-supervisé apprend uniquement à partir des attributs, sans tenir compte des labels. Cela permet par exemple de faire du clustering pour regrouper les données en différentes classes. Nous avons appliqué cette méthode d'apprentissage en utilisant l'algorithme des k-moyennes sur nos données.\\

	L'apprentissage supervisé apprend en se basant sur les attributs mais en utilisant également les labels que nous connaissons. Cette technique d'apprentissage paraît donc plus adaptée dans notre cas. Différentes méthodes existent, nous avons choisis de nous concentrer sur les SVM (\emph{Support Vector Machines} ou séparateurs à vaste marge) pour réaliser notre classification en apprentissage supervisé. Ils sont souvent utilisés pour résoudre des problèmes de discrimination, c'est-à-dire savoir à quelle classe appartient un échantillon, et c'est exactement le problème auquel nous sommes confrontés. Le SVM va chercher à tracer une limite entre les classes des données d'apprentissage en maximisant la marge entre cette limite et chaque classe. Les classes de nouvelles données seront ensuite attribuées selon le côté du quel se trouvent les nouvelles données. La limite entre les classes peut-être en ligne droite, dans le cas d'un SVM linéaire, ou plus compliquée dans le cas d'un SVM avec noyau.\\

	Dans un premier temps nous avons travaillé sur deux classes, ce qui est le problème le plus simple à résoudre avec des SVM. Nous avons pour cela réalisé deux SVM, un svm linéaire et un svm gaussien. Nous avons effectué de la validation croisée afin d'identifier les hyper-paramètres (C pour le svm linéaire, et C et sigma pour le svm gaussien).

	Dans un second temps nous avons travaillé sur un jeu de données contenant 4 classes et des données \emph{unlabeled} représentant une cinquième classe. Les données unlabeled ont été retirées de l'ensemble de l'apprentissage car elle pouvait correspondre à n'importe quelle classe et donc perturber le SVM.
	Nous avons ensuite utilisé deux méthodes permettant de faire de la classification avec plus de deux classes :

	\begin{itemize}
	\item La méthode \emph{one-versus-all} consiste à construire M classifieurs binaires en attribuant le label 1 aux échantillons de l'une des classes et le label -1 à toutes les autres. En phase de test, le classifieur donnant la marge la plus élevée remporte le vote.
	\item La méthode \emph{one-versus-one} consiste à construire M(M-1)/2 classifieurs binaires en confrontant chacune des M classes. En phase de test, l'échantillon à classer est analysé par chaque classifieur et un vote majoritaire permet de déterminer sa classe.\\
	\end{itemize}


\section{Données et pré-traitement}
\subsection{Extraction des données}

	Les données sont extraites à partir de ROS. Il s'agit d'un outil qui sert à traiter les .tm, qui sont des vidéos en 3D, pour en extraire des nuages de points au format pcd. Ici, les vidéos que nous avons sont filmées depuis un véhicule dans une zone urbaine.\\

	Vu qu’il y a des erreurs dans la compilation du C++ pour lancer ROS, M. Guerrero nous a fourni directement les archives contenant les pcd.\\

\subsection{Format des données}

	Les données que nous avons sont une multitude imagettes (frames) de chaque classe. Ce sont des sortes de captures d'écran d'une vidéo à un instant donné, mais en trois dimensions.\\

	Soit$ X_{i}$ la ième imagette, on a :

	$  X_{i} \in \reels^{n_{i}*4} $, avec 50 $\leq n_{i} \leq 300$
	En effet, chaque imagette a ses coordonnées x, y, z et une valeur d'intensité. \\ 

\subsection{Jeu de données dish area}

	Ce jeu de données contient 30242 imagettes réparties dans 91 séquences de 2 classes différentes : background et car.  On remarquera cependant que les données ne sont pas également réparties entre ces classes : il y a 26715 imagettes de la classe background et 3527 de la classe car.

\subsection{Jeu de données lomita}

	Ce jeu de données contient 75817 imagettes réparties dans 155 séquences de 5 classes différentes : background, bicyclist, car, pedestrian et unlabeled. On remarquera cependant que les données ne sont pas également réparties entre ces 5 classes : il y a 105 séquences de classe background, 5 bicyclist, 20 car, 9 pedestrian et 16 unlabeled. \\

	La classe unlabeled n'est pas une classe en soit, elle regroupe les imagettes n'ayant pas pu être classées dans une des 4 autres classes. Ces données ont donc été supprimées du jeu de données car elles auraient pu fausser l'apprentissage. \\

	Nous avons également eu l'idée de ré-équilibrer les classes en utilisant seulement une partie de la classe background mais ce pré-traitement ne semble pas pertinent puisqu'il amène a des taux d'erreur de test plus élevé. C'est pourquoi nous avons gardé des classes déséquilibrées. \\


\section{Résultats obtenus}

Nous n'avons pas pu faire tourner nos algorithmes sur la totalité des données, nos machines n'étant pas assez puissantes. Nous avons donc réduit la taille des données et avons obtenu des résultats déjà satisfaisants. Notre dataset actuel est composé de 1722 observations ayant chacune 10 attributs.

	\subsection{Classification sur deux classes (dish area)}
		\subsubsection{K-moyennes}
			Nous avons utilisé l'algorithme kmeans de matlab pour former des clusters et les comparer avec nos classes. Nous obtenons un taux d'erreur de 8.71\%, ce qui est un bon résultat pour un algorithme non-supervisé. Notre matrice de confusion est la suivante : 

			\begin{center}
				\begin{tabular}{|l||c|c|}
				  \hline
				  & Prédiction : background & Prédiction : car \\
				  \hline
				  Vérité : background & 25054 & 1661 \\
				  \hline
				  Vérité : car & 974 & 2553 \\
				  \hline
				\end{tabular}
			\end{center}

			On constate que les erreurs sont plutôt bien réparties, c'est-à-dire qu'il n'y a pas plus d'erreur pour une classe pour une autre, ce qui était un risque étant donné que nos classes n'ont pas le même effectif.
		\subsubsection{SVM linéaire}
		\subsubsection{SVM gaussien}

	\subsection{Classification sur 4 classes (lomita)}
		\subsubsection{SVM one-versus-one}
		\subsubsection{SVM one-versus-all}
			\begin{itemize}
				\item Noyau polynômial : 4.5\% d'erreur sur 10 runs ; C = 10e9 ; lambda = 1e-6.
				\item Noyau gaussien : 12\% d'erreur sur 10 runs ; C = 10e9 ; lambda = 1e-6.
				\item Noyau gaussien : 8\% d'erreur sur 10 runs ; C = 1 ; lambda = 1e-6.
			\end{itemize}